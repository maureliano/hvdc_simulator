#!/usr/bin/env python3
"""
Script para an√°lise estat√≠stica dos dados experimentais
Gera visualiza√ß√µes e relat√≥rio de pesquisa
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import json

# Configurar estilo
sns.set_style("darkgrid")
plt.rcParams['figure.figsize'] = (14, 10)
plt.rcParams['font.size'] = 10

# Caminho dos dados
data_path = Path(__file__).parent.parent / 'experimental_data.csv'
output_dir = Path(__file__).parent.parent / 'analysis_results'
output_dir.mkdir(exist_ok=True)

print("üìä Carregando dados experimentais...")
df = pd.read_csv(data_path)

print(f"‚úÖ Dados carregados: {len(df)} simula√ß√µes")
print(f"üìã Colunas: {len(df.columns)}")

# ============================================================================
# 1. AN√ÅLISE DESCRITIVA DO IFF
# ============================================================================
print("\n" + "="*70)
print("1. AN√ÅLISE DESCRITIVA DO √çNDICE DE FIDELIDADE F√çSICA (IFF)")
print("="*70)

iff_stats = {
    'M√©dia': df['IFF_indice_fidelidade'].mean(),
    'Mediana': df['IFF_indice_fidelidade'].median(),
    'Desvio Padr√£o': df['IFF_indice_fidelidade'].std(),
    'M√≠nimo': df['IFF_indice_fidelidade'].min(),
    'M√°ximo': df['IFF_indice_fidelidade'].max(),
    'Q1': df['IFF_indice_fidelidade'].quantile(0.25),
    'Q3': df['IFF_indice_fidelidade'].quantile(0.75),
}

for metric, value in iff_stats.items():
    print(f"  {metric:.<20} {value:.6f}")

# ============================================================================
# 2. AN√ÅLISE DE INCERTEZAS
# ============================================================================
print("\n" + "="*70)
print("2. AN√ÅLISE DE INCERTEZAS (œÉ_IFF)")
print("="*70)

uncertainty_stats = {
    'M√©dia': df['sigma_IFF_incerteza'].mean(),
    'M√°xima': df['sigma_IFF_incerteza'].max(),
    'M√≠nima': df['sigma_IFF_incerteza'].min(),
}

for metric, value in uncertainty_stats.items():
    print(f"  {metric:.<20} {value:.6f}")

# ============================================================================
# 3. AN√ÅLISE DE DECIS√ïES AG√äNTICAS
# ============================================================================
print("\n" + "="*70)
print("3. AN√ÅLISE DE DECIS√ïES AG√äNTICAS")
print("="*70)

decisions = df['decisao_agentica'].value_counts()
for decision, count in decisions.items():
    percentage = (count / len(df)) * 100
    print(f"  {decision:.<20} {count:>3} ({percentage:>5.1f}%)")

# ============================================================================
# 4. AN√ÅLISE POR MODO DE FALHA
# ============================================================================
print("\n" + "="*70)
print("4. AN√ÅLISE POR MODO DE FALHA")
print("="*70)

failure_analysis = df.groupby('failure_mode').agg({
    'IFF_indice_fidelidade': ['mean', 'std', 'min', 'max'],
    'sigma_IFF_incerteza': 'mean',
    'decisao_agentica': lambda x: (x == 'BLOCKED').sum(),
}).round(6)

print("\nIFF por Modo de Falha:")
for mode in df['failure_mode'].unique():
    mode_data = df[df['failure_mode'] == mode]
    iff_mean = mode_data['IFF_indice_fidelidade'].mean()
    blocked_count = (mode_data['decisao_agentica'] == 'BLOCKED').sum()
    blocked_pct = (blocked_count / len(mode_data)) * 100
    print(f"  {mode:.<25} IFF={iff_mean:.4f}, Bloqueados={blocked_count} ({blocked_pct:.1f}%)")

# ============================================================================
# 5. AN√ÅLISE POR N√çVEL DE RU√çDO
# ============================================================================
print("\n" + "="*70)
print("5. AN√ÅLISE POR N√çVEL DE RU√çDO")
print("="*70)

print("\nImpacto do Ru√≠do no IFF:")
for noise in sorted(df['noise_level_percent'].unique()):
    noise_data = df[df['noise_level_percent'] == noise]
    iff_mean = noise_data['IFF_indice_fidelidade'].mean()
    sigma_mean = noise_data['sigma_IFF_incerteza'].mean()
    blocked_count = (noise_data['decisao_agentica'] == 'BLOCKED').sum()
    blocked_pct = (blocked_count / len(noise_data)) * 100
    print(f"  Ru√≠do {noise:>2}% - IFF={iff_mean:.4f}, œÉ={sigma_mean:.6f}, Bloqueados={blocked_pct:.1f}%")

# ============================================================================
# 6. AN√ÅLISE DE DIMENS√ïES DE FIDELIDADE
# ============================================================================
print("\n" + "="*70)
print("6. AN√ÅLISE DE DIMENS√ïES DE FIDELIDADE")
print("="*70)

dimensions = {
    'D1 (Estado)': 'D1_fidelidade_estado',
    'D2 (Din√¢mica)': 'D2_fidelidade_dinamica',
    'D3 (Energia)': 'D3_fidelidade_energia',
    'D4 (Estabilidade)': 'D4_fidelidade_estabilidade',
}

for name, col in dimensions.items():
    mean_val = df[col].mean()
    std_val = df[col].std()
    print(f"  {name:.<25} M√©dia={mean_val:.4f}, Desvio={std_val:.4f}")

# ============================================================================
# 7. AN√ÅLISE HIL
# ============================================================================
print("\n" + "="*70)
print("7. AN√ÅLISE HARDWARE-IN-THE-LOOP (HIL)")
print("="*70)

hil_synced = (df['hil_sincronizado'] == 'SIM').sum()
hil_sync_pct = (hil_synced / len(df)) * 100
latency_mean = df['latencia_hil_ms'].mean()
jitter_mean = df['jitter_hil_ms'].mean()

print(f"  Taxa de Sincroniza√ß√£o:.... {hil_sync_pct:.1f}% ({hil_synced}/{len(df)})")
print(f"  Lat√™ncia M√©dia (ms):..... {latency_mean:.2f}")
print(f"  Jitter M√©dio (ms):....... {jitter_mean:.2f}")

# ============================================================================
# GERAR VISUALIZA√á√ïES
# ============================================================================
print("\n" + "="*70)
print("GERANDO VISUALIZA√á√ïES")
print("="*70)

# Figura 1: Distribui√ß√£o de IFF
fig, axes = plt.subplots(2, 2, figsize=(14, 10))
fig.suptitle('An√°lise do √çndice de Fidelidade F√≠sica (IFF)', fontsize=16, fontweight='bold')

# Histograma
axes[0, 0].hist(df['IFF_indice_fidelidade'], bins=30, color='#3b82f6', edgecolor='black', alpha=0.7)
axes[0, 0].axvline(df['IFF_indice_fidelidade'].mean(), color='red', linestyle='--', linewidth=2, label=f'M√©dia: {df["IFF_indice_fidelidade"].mean():.4f}')
axes[0, 0].axvline(0.95, color='green', linestyle='--', linewidth=2, label='Threshold Operacional')
axes[0, 0].axvline(0.90, color='orange', linestyle='--', linewidth=2, label='Threshold Warning')
axes[0, 0].set_xlabel('IFF')
axes[0, 0].set_ylabel('Frequ√™ncia')
axes[0, 0].set_title('Distribui√ß√£o de IFF')
axes[0, 0].legend()
axes[0, 0].grid(True, alpha=0.3)

# Box plot por decis√£o
df_plot = df.copy()
df_plot['decisao_agentica'] = pd.Categorical(df_plot['decisao_agentica'], categories=['OPERATIONAL', 'WARNING', 'BLOCKED'], ordered=True)
sns.boxplot(data=df_plot, x='decisao_agentica', y='IFF_indice_fidelidade', ax=axes[0, 1], palette=['green', 'orange', 'red'])
axes[0, 1].set_title('IFF por Decis√£o Ag√™ntica')
axes[0, 1].set_ylabel('IFF')
axes[0, 1].set_xlabel('Decis√£o')
axes[0, 1].grid(True, alpha=0.3, axis='y')

# IFF vs Ru√≠do
noise_data = df.groupby('noise_level_percent')['IFF_indice_fidelidade'].agg(['mean', 'std'])
axes[1, 0].errorbar(noise_data.index, noise_data['mean'], yerr=noise_data['std'], marker='o', capsize=5, capthick=2, linewidth=2, markersize=8, color='#3b82f6')
axes[1, 0].fill_between(noise_data.index, noise_data['mean'] - noise_data['std'], noise_data['mean'] + noise_data['std'], alpha=0.2, color='#3b82f6')
axes[1, 0].set_xlabel('N√≠vel de Ru√≠do (%)')
axes[1, 0].set_ylabel('IFF')
axes[1, 0].set_title('Impacto do Ru√≠do no IFF')
axes[1, 0].grid(True, alpha=0.3)

# Incerteza vs Ru√≠do
uncertainty_data = df.groupby('noise_level_percent')['sigma_IFF_incerteza'].mean()
axes[1, 1].plot(uncertainty_data.index, uncertainty_data.values, marker='s', linewidth=2, markersize=8, color='#ef4444')
axes[1, 1].set_xlabel('N√≠vel de Ru√≠do (%)')
axes[1, 1].set_ylabel('œÉ_IFF')
axes[1, 1].set_title('Propaga√ß√£o de Incerteza vs Ru√≠do')
axes[1, 1].grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig(output_dir / 'iff_analysis.png', dpi=300, bbox_inches='tight')
print("‚úÖ Salvo: iff_analysis.png")
plt.close()

# Figura 2: An√°lise de Dimens√µes
fig, axes = plt.subplots(2, 2, figsize=(14, 10))
fig.suptitle('An√°lise das Dimens√µes de Fidelidade', fontsize=16, fontweight='bold')

for idx, (name, col) in enumerate(dimensions.items()):
    ax = axes[idx // 2, idx % 2]
    ax.hist(df[col], bins=25, color='#10b981', edgecolor='black', alpha=0.7)
    ax.axvline(df[col].mean(), color='red', linestyle='--', linewidth=2, label=f'M√©dia: {df[col].mean():.4f}')
    ax.set_xlabel(name)
    ax.set_ylabel('Frequ√™ncia')
    ax.set_title(f'Distribui√ß√£o de {name}')
    ax.legend()
    ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig(output_dir / 'dimensions_analysis.png', dpi=300, bbox_inches='tight')
print("‚úÖ Salvo: dimensions_analysis.png")
plt.close()

# Figura 3: An√°lise de Modos de Falha
fig, axes = plt.subplots(1, 2, figsize=(14, 5))
fig.suptitle('An√°lise de Modos de Falha', fontsize=16, fontweight='bold')

# IFF por modo de falha
failure_iff = df.groupby('failure_mode')['IFF_indice_fidelidade'].mean().sort_values()
axes[0].barh(failure_iff.index, failure_iff.values, color='#8b5cf6', edgecolor='black', alpha=0.7)
axes[0].set_xlabel('IFF M√©dio')
axes[0].set_title('IFF M√©dio por Modo de Falha')
axes[0].grid(True, alpha=0.3, axis='x')

# Decis√µes por modo de falha
failure_decisions = pd.crosstab(df['failure_mode'], df['decisao_agentica'], normalize='index') * 100
failure_decisions = failure_decisions[['OPERATIONAL', 'WARNING', 'BLOCKED']]
failure_decisions.plot(kind='bar', ax=axes[1], color=['green', 'orange', 'red'], alpha=0.7, edgecolor='black')
axes[1].set_ylabel('Percentual (%)')
axes[1].set_xlabel('Modo de Falha')
axes[1].set_title('Distribui√ß√£o de Decis√µes por Modo de Falha')
axes[1].legend(title='Decis√£o')
axes[1].grid(True, alpha=0.3, axis='y')
plt.setp(axes[1].xaxis.get_majorticklabels(), rotation=45, ha='right')

plt.tight_layout()
plt.savefig(output_dir / 'failure_modes_analysis.png', dpi=300, bbox_inches='tight')
print("‚úÖ Salvo: failure_modes_analysis.png")
plt.close()

# Figura 4: An√°lise HIL
fig, axes = plt.subplots(2, 2, figsize=(14, 10))
fig.suptitle('An√°lise Hardware-in-the-Loop (HIL)', fontsize=16, fontweight='bold')

# Lat√™ncia vs IFF
axes[0, 0].scatter(df['latencia_hil_ms'], df['IFF_indice_fidelidade'], alpha=0.6, s=50, color='#3b82f6')
axes[0, 0].set_xlabel('Lat√™ncia (ms)')
axes[0, 0].set_ylabel('IFF')
axes[0, 0].set_title('Lat√™ncia vs IFF')
axes[0, 0].grid(True, alpha=0.3)

# Jitter vs IFF
axes[0, 1].scatter(df['jitter_hil_ms'], df['IFF_indice_fidelidade'], alpha=0.6, s=50, color='#f59e0b')
axes[0, 1].set_xlabel('Jitter (ms)')
axes[0, 1].set_ylabel('IFF')
axes[0, 1].set_title('Jitter vs IFF')
axes[0, 1].grid(True, alpha=0.3)

# Distribui√ß√£o de Lat√™ncia
axes[1, 0].hist(df['latencia_hil_ms'], bins=25, color='#3b82f6', edgecolor='black', alpha=0.7)
axes[1, 0].axvline(df['latencia_hil_ms'].mean(), color='red', linestyle='--', linewidth=2, label=f'M√©dia: {df["latencia_hil_ms"].mean():.2f} ms')
axes[1, 0].set_xlabel('Lat√™ncia (ms)')
axes[1, 0].set_ylabel('Frequ√™ncia')
axes[1, 0].set_title('Distribui√ß√£o de Lat√™ncia HIL')
axes[1, 0].legend()
axes[1, 0].grid(True, alpha=0.3)

# Sincroniza√ß√£o HIL
hil_sync_counts = df['hil_sincronizado'].value_counts()
colors = ['green' if x == 'SIM' else 'red' for x in hil_sync_counts.index]
axes[1, 1].bar(hil_sync_counts.index, hil_sync_counts.values, color=colors, alpha=0.7, edgecolor='black')
axes[1, 1].set_ylabel('Contagem')
axes[1, 1].set_title('Status de Sincroniza√ß√£o HIL')
for i, v in enumerate(hil_sync_counts.values):
    axes[1, 1].text(i, v + 2, str(v), ha='center', fontweight='bold')
axes[1, 1].grid(True, alpha=0.3, axis='y')

plt.tight_layout()
plt.savefig(output_dir / 'hil_analysis.png', dpi=300, bbox_inches='tight')
print("‚úÖ Salvo: hil_analysis.png")
plt.close()

# ============================================================================
# SALVAR RELAT√ìRIO JSON
# ============================================================================
print("\n" + "="*70)
print("SALVANDO RELAT√ìRIO JSON")
print("="*70)

report = {
    'metadata': {
        'total_simulations': len(df),
        'timestamp_gerado': pd.Timestamp.now().isoformat(),
    },
    'iff_statistics': {k: float(v) for k, v in iff_stats.items()},
    'uncertainty_statistics': {k: float(v) for k, v in uncertainty_stats.items()},
    'decisions_distribution': decisions.to_dict(),
    'failure_modes_distribution': df['failure_mode'].value_counts().to_dict(),
    'scenarios_distribution': df['scenario'].value_counts().to_dict(),
    'hil_metrics': {
        'sync_rate_percent': float(hil_sync_pct),
        'latency_mean_ms': float(latency_mean),
        'jitter_mean_ms': float(jitter_mean),
    },
    'dimensions_statistics': {
        name: {
            'mean': float(df[col].mean()),
            'std': float(df[col].std()),
            'min': float(df[col].min()),
            'max': float(df[col].max()),
        }
        for name, col in dimensions.items()
    },
}

with open(output_dir / 'experimental_report.json', 'w') as f:
    json.dump(report, f, indent=2)

print("‚úÖ Salvo: experimental_report.json")

print("\n" + "="*70)
print("‚ú® AN√ÅLISE CONCLU√çDA COM SUCESSO!")
print("="*70)
print(f"\nüìÅ Resultados salvos em: {output_dir}")
print(f"   - iff_analysis.png")
print(f"   - dimensions_analysis.png")
print(f"   - failure_modes_analysis.png")
print(f"   - hil_analysis.png")
print(f"   - experimental_report.json")
